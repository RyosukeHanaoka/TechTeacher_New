{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAgjUmC4Mx/R8t97btX7G+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyosukeHanaoka/TechTeacher_New/blob/main/vit_eval_with_gradcam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOGpIUC4qnY_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import timm\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from captum.attr import LayerGradCam\n",
        "from captum.attr import visualization as viz\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImagePreprocessor:\n",
        "    def __init__(self, size=(224, 224), mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]):\n",
        "        self.size = size\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize(self.size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=self.mean, std=self.std)\n",
        "        ])\n",
        "\n",
        "    def process_image(self, image_path, flip_left_hand=False):\n",
        "        image = Image.open(image_path)\n",
        "        if flip_left_hand:\n",
        "            image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        image = image.convert('RGB')\n",
        "        image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "class RheumatoidArthritisModel:\n",
        "    def __init__(self, checkpoint_path, model_name='vit_base_patch16_224_in21k'):\n",
        "        self.model = timm.create_model(model_name, pretrained=False, num_classes=2)\n",
        "        self.checkpoint_path = checkpoint_path\n",
        "        self.load_checkpoint()\n",
        "        self.model.eval()\n",
        "\n",
        "    def load_checkpoint(self):\n",
        "        checkpoint = torch.load(self.checkpoint_path, map_location=torch.device('cpu'))\n",
        "        self.model.load_state_dict(checkpoint)\n",
        "\n",
        "    def predict(self, image_tensor):\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(image_tensor.unsqueeze(0))\n",
        "        return outputs\n",
        "\n",
        "def reshape_transform(tensor, height=14, width=14):\n",
        "    result = tensor[:, 1:, :].reshape(tensor.size(0), height, width, tensor.size(2))\n",
        "    result = result.transpose(2, 3).transpose(1, 2)\n",
        "    return result\n",
        "\n",
        "def overlay_cam_on_image(img, cam):\n",
        "    cam = cv2.resize(cam, (img.shape[1], img.shape[0]))\n",
        "    cam = (cam - cam.min()) / (cam.max() - cam.min())  # 正規化\n",
        "    cam = np.uint8(255 * cam)\n",
        "    cam = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\n",
        "    img = np.float32(img) / 255\n",
        "    overlayed_img = cam * 0.4 + img\n",
        "    return np.uint8(255 * overlayed_img)\n",
        "\n",
        "def main():\n",
        "    input_directory_righthand = \"/content/drive/MyDrive/image_righthand\"\n",
        "    output_directory_righthand = \"/content/drive/MyDrive/converted_righthand\"\n",
        "    input_directory_lefthand = \"/content/drive/MyDrive/image_lefthand\"\n",
        "    output_directory_lefthand = \"/content/drive/MyDrive/converted_lefthand\"\n",
        "\n",
        "    preprocessor = ImagePreprocessor()\n",
        "\n",
        "    right_hand_image_path = os.path.join(output_directory_righthand, \"sample.jpg\")\n",
        "    left_hand_image_path = os.path.join(output_directory_lefthand, \"sample.jpg\")\n",
        "\n",
        "    right_hand_image = preprocessor.process_image(right_hand_image_path)\n",
        "    left_hand_image = preprocessor.process_image(left_hand_image_path, flip_left_hand=True)\n",
        "\n",
        "    checkpoint_path = \"/content/drive/MyDrive/OptPhotoFiles/model.pth\"\n",
        "    model = RheumatoidArthritisModel(checkpoint_path)\n",
        "\n",
        "    right_hand_prediction = model.predict(right_hand_image)\n",
        "    left_hand_prediction = model.predict(left_hand_image)\n",
        "\n",
        "    print(\"Right Hand Prediction:\", right_hand_prediction)\n",
        "    print(\"Left Hand Prediction:\", left_hand_prediction)\n",
        "\n",
        "    if torch.argmax(right_hand_prediction) == 1 or torch.argmax(left_hand_prediction) == 1:\n",
        "        print(\"Rheumatoid Arthritis Detected\")\n",
        "\n",
        "        target_layer = model.model.blocks[-1].norm1  # ターゲットレイヤーを指定\n",
        "\n",
        "        # Captumを使用してLayerGradCamを初期化\n",
        "        cam = LayerGradCam(model.model, target_layer)\n",
        "\n",
        "        rgb_img_right = cv2.imread(right_hand_image_path, 1)[:, :, ::-1]\n",
        "        rgb_img_right = cv2.resize(rgb_img_right, (224, 224))\n",
        "        input_tensor_right = preprocessor.process_image(right_hand_image_path)\n",
        "\n",
        "        rgb_img_left = cv2.imread(left_hand_image_path, 1)[:, :, ::-1]\n",
        "        rgb_img_left = cv2.resize(rgb_img_left, (224, 224))\n",
        "        input_tensor_left = preprocessor.process_image(left_hand_image_path, flip_left_hand=True)\n",
        "\n",
        "        # GradCAMの生成結果をデバッグ出力\n",
        "        grayscale_cam_right = cam.attribute(input_tensor_right.unsqueeze(0), target=torch.argmax(right_hand_prediction).item()).squeeze().cpu().detach().numpy()\n",
        "        print(\"Grayscale CAM Right Shape:\", grayscale_cam_right.shape)\n",
        "\n",
        "        cam_image_right = overlay_cam_on_image(rgb_img_right, grayscale_cam_right)\n",
        "\n",
        "        grayscale_cam_left = cam.attribute(input_tensor_left.unsqueeze(0), target=torch.argmax(left_hand_prediction).item()).squeeze().cpu().detach().numpy()\n",
        "        print(\"Grayscale CAM Left Shape:\", grayscale_cam_left.shape)\n",
        "\n",
        "        cam_image_left = overlay_cam_on_image(rgb_img_left, grayscale_cam_left)\n",
        "\n",
        "        # デバッグのためのオーバーレイ画像の確認\n",
        "        plt.imshow(cam_image_right)\n",
        "        plt.show()\n",
        "        plt.imshow(cam_image_left)\n",
        "        plt.show()\n",
        "\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(\"Right Hand\")\n",
        "        plt.imshow(cam_image_right)\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.title(\"Left Hand\")\n",
        "        plt.imshow(cam_image_left)\n",
        "        plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "1wJyqDXHqw0H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}